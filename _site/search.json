[
  {
    "objectID": "til.html",
    "href": "til.html",
    "title": "Today I Learned",
    "section": "",
    "text": "Title\n\n\nDate\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talk.html",
    "href": "talk.html",
    "title": "Talks",
    "section": "",
    "text": "Title\n\n\nDate\n\n\nDescription\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "tutorial\n\n\n\n\nWelcome to my Blog\n\n\n\n\n\n\nApr 18, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/average-hike/index.html",
    "href": "blog/average-hike/index.html",
    "title": "Taking a peek into my hiking data",
    "section": "",
    "text": "Thomas Moran, Winter in the Rockies (1867)\nI moved to Seattle at the end of 2016 and since then have done over 100 hikes (depending on your definition of ‚Äòa hike‚Äô). I must admit I‚Äôve been abysmal at tracking any data regarding my hiking activity beyond a Google spreadsheet, despite the ubiquity of trail tracking apps that exist.\nRecently, I signed up on AllTrails to start collecting data on my hikes. The Pro service offers many wonderful features, including the ability to download GPX data on hikes. I was so excited by this that I decided to try to visualize the hikes I have done.\nI ran a poll on Twitter in which I asked whether people embed code in the main text of their blog post or at the end. 91% embed in the main text [n = 85]. I structured this post accordingly."
  },
  {
    "objectID": "blog/average-hike/index.html#pulling-data",
    "href": "blog/average-hike/index.html#pulling-data",
    "title": "Taking a peek into my hiking data",
    "section": "Pulling data",
    "text": "Pulling data\n\nChoose packages\nIt took a bit to decide which packages had the functions needed to run the spatial analyses. In the end, I decided on:\n\nplotKML: A package containing functions to read GPX files.\ngeosphere: A package containing functions for geospatial calculations. I decided to use this for finding out distances between lon/lat.\ngoogleway: A package allowing access to the Google Maps API. To run this, you need to obtain a Google Maps API key and load it to R by using set_key(). I use this for elevation calculations but the API can also obtain the distance between points.\n\n\nlibrary(tidyverse)\nlibrary(googleway)\nlibrary(plotKML)\nlibrary(geosphere)\n\ngoogleway::set_key(API_KEY_HERE)\n\n\n\nTidy data\nI downloaded each GPX file from AllTrails and saved them in a file in my project organization. Their file names were TRAILNAME.gpx.\n\nUsing plotKML::readGPX() results in the files being loaded as lists.\nI used purrr in conjunction with plotKML() to handily read them in and add the file name to the list.\n\n\n# find gpx files\ndata_path <- \n  here::here(\"data\", \"raw\", \"gpx_files\")\n\nfiles <-\n  dir(data_path, pattern = \"*.gpx\", full.names = TRUE)\n\n# get trail names\nnames <-\n  dir(data_path, pattern = \"*.gpx\", full.names = FALSE) %>% \n  str_extract(\".+?(?=.gpx)\")\n\n# read all gpx files\ngpx_dat <-\n  map2(files,\n       names,\n       ~ readGPX(.x,\n         metadata = TRUE,\n         bounds = TRUE,\n         waypoints = TRUE,\n         tracks = TRUE,\n         routes = TRUE) %>%\n         list_modify(trail = .y)) # otherwise you can't tell which entry is for which trail\n\n\n\nCalculate elevation\nWe can use googleway::google_elevation() to access the Google Elevation API and calculate elevation for every lon/lat pair from the GPX files. Unfortunately, the API accepts and returns only a few requests at a time (~200 rows for these files). We have over 51,000 rows of data. So, we can create groups for every 200 rows and use a loop to make a call for each\nThis results in a list, so we can then create a tibble pulling out the data we want.\n\nlonlat_dat <-\n  gpx_dat %>%\n  map_df(., ~.x$\"routes\"[[1]], .id = \"trail\") %>%\n  select(trail, lon, lat) %>% \n  group_by(trail) %>% \n  ungroup() %>% \n  mutate(group_number = (1:nrow(.) %/% 200) + 1) # https://stackoverflow.com/questions/32078578/how-to-group-by-every-7-rows-and-aggregate-those-7-values-by-median\n\ndat_lapply <- lapply(1:max(lonlat_dat$group_number), function(x) {\n  Sys.sleep(3)\n  \n  lonlat_dat %>%\n    filter(group_number == x) %>% # added a filter so you only pull a subset of the data.\n    do(elev_dat =\n         data.frame(\n           google_elevation(\n             df_locations = dplyr::select(., lon, lat),\n             location_type = \"individual\",\n             simplify = TRUE)))\n  })\n\ndat_lapply_elev_dat <-\n  dat_lapply %>%\n  map(., ~ .x$\"elev_dat\"[[1]])\n\nelev_df <-\n  dat_lapply_elev_dat %>% {\n    tibble(\n      elevation = map(., ~ .x$\"results.elevation\"),\n      lon = map(., ~ .x$\"results.location\"[[\"lng\"]]),\n      lat = map(.,  ~ .x$\"results.location\"[[\"lat\"]])\n    )\n  } %>% \n  unnest(.id = \"group_number\") %>% \n  select(group_number, elevation, lon, lat)\n\n\n\nCalculate distance\nNow we have a list of trails, longitudes and latitudes along their paths, and the elevation for each of those points. Now we want to calculate the distance along the paths.\n\nWe bring back lonlat_dat so we know what trails with which each point are associated.\nTo use calculate distance, we can use distHaversine() with two sets of lon/lat. We create the second set of lon/lat by creating a new variable that takes the ‚Äúnext‚Äù value in a vector (so we‚Äôre calculating the distance between point A and point B, point B to point C, and so on).\ncumsum() accumulates the distances between each set of lon/lat.\nFinally, we calculate the elevation gain for each hike.\n\n\nhiking_dat <-\n  plyr::join(elev_df, lonlat_dat, type = \"left\", match = \"first\") %>% \n  group_by(trail) %>% \n  mutate(elev_feet = elevation * 3.281, # to convert to feet\n         lon2 = lead(lon, 1),\n         lat2 = lead(lat, 1)) %>%\n  ungroup() %>% \n  mutate(dist = distHaversine(hiking_dat[, 2:3], hiking_dat[, 7:8])/1609.344) %>% # to convert to miles\n  group_by(trail) %>% \n  mutate(cumdist = cumsum(dist),\n         elev_gain = elev_feet - first(elev_feet)) %>%\n  ungroup()\n\n\n\nCreate additional tables\nFor nerdy kicks, I also wanted to find out my ‚Äòaverage‚Äô hike - that is, the average distance, the average elevation, and the average elevation for each distance. I also wanted to see the total distance and elevation for each trail for which I pulled data.\n\navg_elev <- # average elevation by distance\n  hiking_dat %>% \n  group_by(round(cumdist, 1)) %>% \n  summarize(mean(elev_gain))\n\nhiking_dat_by_trail <- # total gain/distance by trail\n  hiking_dat %>% \n  select(trail, cumdist, elev_gain) %>% \n  group_by(trail) %>%\n  summarize(tot_dist = max(cumdist, na.rm = T),\n            tot_elev_gain = max(elev_gain)) %>% \n  mutate(tot_dist_scaled = scale(tot_dist), # for cluster analysis\n         tot_elev_scaled = scale(tot_elev_gain))"
  },
  {
    "objectID": "blog/average-hike/index.html#creating-visualizations",
    "href": "blog/average-hike/index.html#creating-visualizations",
    "title": "Taking a peek into my hiking data",
    "section": "Creating visualizations",
    "text": "Creating visualizations"
  },
  {
    "objectID": "blog/average-hike/index.html#disclaimer",
    "href": "blog/average-hike/index.html#disclaimer",
    "title": "Taking a peek into my hiking data",
    "section": "Disclaimer",
    "text": "Disclaimer\nFor data collection, I downloaded each trail‚Äôs GPX files from AllTrails. Because these data are proprietary, I will not be providing them. Some things to note:\n\nBecause these are data pulled from the website, they are not indicative of my actual hiking path (for example, Franklin Falls is a 2-mile hike in the summer, but in the winter is a 6-mile snowshoe).\nThere are hikes that I did back-to-back that I‚Äôd consider one hike but the trails might be listed separately on the site. For example, Deception Pass is actually made up of three small loops."
  },
  {
    "objectID": "blog/average-hike/index.html#the-hikes-are-wide-and-varied",
    "href": "blog/average-hike/index.html#the-hikes-are-wide-and-varied",
    "title": "Taking a peek into my hiking data",
    "section": "The hikes are wide and varied",
    "text": "The hikes are wide and varied\nBeing fortunate enough to live near multiple mountain ranges, the hikes come in all shapes and sizes.\n\nggplot() + \n  geom_density_ridges(data = na.omit(hiking_dat),\n                      aes(x = cumdist,\n                          y = trail,\n                          group = trail),\n                      fill = \"#00204c\",\n                      rel_min_height = 0.01\n                      ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\nI calculated my ‚Äòaverage hike‚Äô - that is, the average elevation given the cumulative distance traveled.\n\nggplot() + \n  geom_ridgeline(data = hiking_dat,\n                 aes(x = cumdist,\n                     y = trail,\n                     group = trail,\n                     height = elev_gain),\n                 color = \"#c9b869\",\n                 alpha = 0) +\n  geom_line(data = avg_elev,\n            aes(x = `round(cumdist, 1)`,\n                y = `mean(elev_gain)`),\n            color = \"#00204c\",\n            size = 2) +\n  scale_x_continuous(name = \"Cumulative Distance (miles)\") +\n  scale_y_continuous(name = \"Cumulative Elevation (ft)\", limits = c(0, 5000)) +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "blog/average-hike/index.html#aggregated-data-by-trail",
    "href": "blog/average-hike/index.html#aggregated-data-by-trail",
    "title": "Taking a peek into my hiking data",
    "section": "Aggregated Data by Trail",
    "text": "Aggregated Data by Trail\nIn the aggregate, there seems to be a correlation (r^2 = 0.48) between total distance and total elevation.\n\nggplot() + \n  geom_point(data = hiking_dat_by_trail,\n             aes(x = tot_dist,\n                 y = tot_elev_gain,\n                 color = tot_elev_gain,\n                 size = tot_dist)) +\n  scale_x_continuous(name = \"Total Distance (miles)\") +\n  scale_y_continuous(name = \"Total Elevation (ft)\") +\n  scale_color_viridis(option = \"cividis\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "blog/average-hike/index.html#there-exist-clusters-of-hikes",
    "href": "blog/average-hike/index.html#there-exist-clusters-of-hikes",
    "title": "Taking a peek into my hiking data",
    "section": "There exist ‚Äúclusters‚Äù of hikes",
    "text": "There exist ‚Äúclusters‚Äù of hikes\nI ran a quick cluster analysis to see if I can categorize my hikes in any way. Code is in the Methodology section. Four clusters seemed to be optimal. I have dubbed them:\n\nCluster 1: ‚ÄúLet‚Äôs Get This Over With‚Äù (steep & hard)\nCluster 2: ‚ÄúEasy Peasy Lemon Squeezy‚Äù (short & flat)\nCluster 3: ‚ÄúThe Sweet Spot‚Äù (not too long, not too high)\nCluster 4: ‚ÄúI Don‚Äôt Care About My Knees Anyway‚Äù (too long for my own good)\n\n\nfviz_nbclust(hiking_dat_by_trail[, 4:5], kmeans, method = \"wss\") # finding optimal number of clusters\nk4 <- kmeans(hiking_dat_by_trail[, 4:5], centers = 4, nstart = 25) # calculating clusters\n\nfviz_cluster(k4, data = hiking_dat_by_trail)  +\n  scale_x_continuous(name = \"Scaled Total Distance (miles)\") +\n  scale_y_continuous(name = \"Scaled Total Elevation (ft)\") +\n  scale_color_viridis(option = \"cividis\", discrete = T) +\n  scale_fill_viridis(option = \"cividis\", discrete = T) +\n  theme_minimal()"
  },
  {
    "objectID": "blog/average-hike/index.html#i-dont-particularly-love-long-hikes",
    "href": "blog/average-hike/index.html#i-dont-particularly-love-long-hikes",
    "title": "Taking a peek into my hiking data",
    "section": "I don‚Äôt particularly love long hikes",
    "text": "I don‚Äôt particularly love long hikes\nMy average hike is 6.4 miles - and most of them are concentrated around that distance. This makes sense as I usually day hike and need to get back at a reasonable time. My shortest hike was 1.18 miles and my longest was 17.85 (the Enchantments‚Ä¶). In these 90 hikes, I hiked around 576 miles.\n\nhiking_dat_by_trail %>% \n  ggplot(aes(x = tot_dist)) +\n  geom_histogram(fill = \"#00204c\") +\n  xlab(\"Trail Total Distance (miles)\") +\n  ylab(\"Count\") +\n  scale_fill_viridis(option = \"cividis\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\nHistogram of hike total distance\n\n\n\nhiking_dat_by_trail %>% \n  mutate(cumdist = cumsum(tot_dist)) %>% \n  ggplot(aes(x = trail,\n             y = cumdist,\n             fill = cumdist)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_viridis(option = \"cividis\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\nCumulative bar plot of distance"
  },
  {
    "objectID": "blog/average-hike/index.html#i-dont-dislike-high-elevation-hikes-though",
    "href": "blog/average-hike/index.html#i-dont-dislike-high-elevation-hikes-though",
    "title": "Taking a peek into my hiking data",
    "section": "I don‚Äôt dislike high elevation hikes though",
    "text": "I don‚Äôt dislike high elevation hikes though\nElevation on these hikes ranged from ~0 feet to 4580 feet gain. I averaged 1455.4 feet gain and have climbed 130,984 feet (~24 miles!).\n\nhiking_dat_by_trail %>% \n  ggplot(aes(x = tot_elev_gain)) +\n  geom_histogram(fill = \"#00204c\") +\n  xlab(\"Trail Total Elevation (ft)\") +\n  ylab(\"Count\") +\n  scale_fill_viridis(option = \"cividis\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\nhiking_dat_by_trail %>% \n  mutate(cumelev = cumsum(tot_elev_gain)) %>% \n  ggplot(aes(x = trail,\n             y = cumelev,\n             fill = cumelev)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_viridis(option = \"cividis\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\nLiked this article? I‚Äôd love for you to retweet!\n\n\nNew blog post üéâ: Taking A Peek into My Hiking Data accessing Google Maps API with googleway ‚õ∞Ô∏èüó∫ https://t.co/2foOUgPKIy #rstats pic.twitter.com/pEevVI9uxN\n\n‚Äî Isabella Vel√°squez (@ivelasq3) May 6, 2019"
  },
  {
    "objectID": "blog/firstblog/index.html",
    "href": "blog/firstblog/index.html",
    "title": "My First Quatro Post",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Shamsudeeen Muhammad‚Äôs Blog",
    "section": "",
    "text": "I a PhD student at the University of Porto, Portugal."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "This is my personal website. Nothing here is endorsed by my employer or any organizations of which I am a part. Content on this site is provided under a Creative Commons (CC-BY) 4.0 license. You may reuse this content as long as you indicate my authorship and provide a link back to the original material. Source code of the site is provided under the MIT license and may be reused without restriction."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Projects",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "project.html#books",
    "href": "project.html#books",
    "title": "Projects",
    "section": "Books",
    "text": "Books\n\n\n\n\n\n\n\n\n\n\nIntroduction to Statistical Learning in Python and Tidymodel\n\n\nSolution for Introduction to Statistical Learning in Python and Tidymodel.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talk/blogdown-for-what/index.html",
    "href": "talk/blogdown-for-what/index.html",
    "title": "Blogdown for What",
    "section": "",
    "text": "Hello everybody. My name is Isabella Velasquez. I am very excited to talk to you today about the package blogdown. I‚Äôve decided to call this presentation: BLOGDOWN FOR WHAT?\nA little about me: I‚Äôm Isabella. I‚Äôm a data analyst at the Bill & Melinda Gates Foundation along with R-Ladies Seattle organizer, Chaya. I started learning R in 2015 when attending graduate school at the University of Chicago. We were pretty much thrust into the R world and had to sink or swim, which is how I approach this talk. I try to be as straightforward as possible in my work and hopefully that is reflected in this presentation. This is meant to be a simple introduction on blogdown, why you should use it, and how to get set up.\nLet‚Äôs start at the beginning. Why even have a website at all? It‚Äôs something that I think about a lot because sharing my thoughts and work is not something that comes naturally to me. Although I am not a prolific Twitter user or blogger, I do have accounts and try to keep up with the R world as best I can. Like I mentioned, I started learning R in graduate school. It‚Äôs been three years and I have vague recollections of my R journey. But with a website, I would have been able to clearly see how my analysis of data has evolved and improved. I could see how I moved from the data cleaning steps, summary statistics, visualization of different projects instead of just speculating when I go through all my various files. I also have all my projects in multiple places right now ‚Äì on my laptop, on my work laptop, on my GitHub. If I wanted to find what I‚Äôve done and share it with others, it would be quite a lift. A website can be the holder of all that information. And finally, there is nothing more valuable than sharing what you‚Äôve done with others to get feedback. You get to see any gaps you missed, new ideas you may not have thought of, or how to continue your work and do more interesting, fun things. The R community is so vibrant and collaborative that you get to explore that with many many people around the world.\nEnter blogdown. Blogdown is an R package that makes websites using R Markdown, which is a file format for documents, and Hugo, which is a static website generator. You can create the website entirely in R Studio. If you use GitHub, then you can upload your work to a repository and have version control readily available. And if you use GitHub, you can link your blogdown website with Netlify, which will easily publish your website.\nSo, blogdown for what? There are many options out there for creating websites. And that‚Äôs exactly the issue: there are many options out there for creating websites. There are many factors to consider, like whether your images will load quickly and how easy it is to create a new post. Blogdown considers all these factors and creates a fast, safe, easy to use website.\nBecause we‚Äôre talking about using R, which presumably means there will be data analysis involved. R Markdown is a format that easily details data analysis. It has code chunks so that you can see the actual code that you write and then it also displays the output, whether it be a table or image. But then it‚Äôs also easy to write in your commentary in regular text. Therefore, if you are using your website to show off your analysis and R skills, then R Markdown is a great format to do that in. However, the other very commonly used website creator Jekyll does not display R Markdown files very easily and unfortunately R Markdown isn‚Äôt great for creating websites on its own. Blogdown puts all the necessary steps in place to create a website that easily displays R Markdown pages.\nThe other great thing is that because blogdown also embeds Hugo, there are many themes available that are visually appealing even without customization. And if you do know how to customize websites, then the sky is the limit.\nSo how do you actually make a website with blogdown? The creator of the package, Yihui Xie, and his coauthors Amber Thomas and Alison Presmanes Hill luckily wrote a guide that walks through every step in detail. When creating my website, I just went through each page and followed the instructions. It‚Äôs that easy! But like I mentioned earlier, I want to give you the most straightforward introduction that I can.\nBefore we begin, make sure you already have RStudio and GitHub. Chaya recently gave a talk on GitHub and walked through creating a repository and linking to a project in R Studio. You can create a blogdown website without linking to GitHub, but in addition to all the benefits that GitHub provides, like version control, it will also allow you to host on Netlify easily later on.\nOnce you have a project in R Studio, you want to have blogdown installed!\nAnd because the creators of blogdown have done such a good job making their package user friendly, once you have blogdown installed you actually don‚Äôt have to create a project with code although you can do whatever works for you. I just go into New Project then New Directory then create a Website using Blogdown. I like this add-in because if you use the same directory name as the project you cloned from R Studio, then all the blogdown folders will be created in that directory and then you can commit and push up to GitHub. This add-in also lets you install your theme if you don‚Äôt want the default one.\nOnce you have your new website project, you must run serve site in order to preview it within R Studio. Then you can start customizing within the file config.toml which is created when you create a site. Here, you can put things like your name, your Twitter handle. And once you are ready to create a new post, type new post in the console and run. It will populate an R Markdown file that you can fill in to your liking. And once all that is ready, you can commit and push up to GitHub!\nLike I mentioned before, if you want an actual URL that people can go to, you can use Netlify for hosting. If you have pushed everything up to GitHub, you can connect netlify with your website repository and your webiste will update anytime you push up to GitHub. Netlify gives out a weird URL, which you can change but if you want to do even more things R, you can apply for an rbind.io URL. They have a request template where you list out your Netlify account and GitHub repo and desired URL and they got back to me in a day.\nIn terms of troubleshooting, I ran into an issue where my website wasn‚Äôt loading the way that it did in the R Studio preview window. I ran a quick Google search saying just that and saw that there was already a thread about it. I read through it, followed the instructions, and was able to fix it.\nI mention that because there are so many resources for blogdown even in the few months it has been out. Beyond the official guide, Mara Averick works hard to compile resources and tutorials. StackOverflow has a blogdown tag. And many things are just a search away.\nThanks all for listening. I hope this presentation showed you why you should have a site, in particular a blogdown one, and how to create one. Hopefully I‚Äôve also shown you that there‚Äôs a lot of help out there and they continue to make blogdown more user friendly all the time. And finally here is my blogdown site‚Ä¶with all the neat Hugo functionalities!"
  },
  {
    "objectID": "project/book/data-science-in-education-using-r/index.html",
    "href": "project/book/data-science-in-education-using-r/index.html",
    "title": "Introduction to Statistical Learning in Python and Tidymodel",
    "section": "",
    "text": "Coming soon !!!"
  },
  {
    "objectID": "project/book/index.html",
    "href": "project/book/index.html",
    "title": "Introduction to Statistical Learning in Python and Tidymodel",
    "section": "",
    "text": "Coming soon !!!"
  }
]