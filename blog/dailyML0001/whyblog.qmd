---
title: "Dimentionality Reduction in Machine Learning?"
format:
  html:
    code-fold: true
image: featured.jpg
date: "2022-05-17"
categories:   
  - DailyML
  - Bnomial
description: "Welcome to my Quarto Blog"
---

## Question of the day : Riley's speed-dating match

If you spend all day sitting at a desk, you can't expect to have many opportunities to meet interesting people.

Riley decided to get to bull by the horns and checked in on one of those speed-dating sites that promise to find your perfect match.

But of course, Silicon Valley is a ridiculous caricature of the impossible, and Riley's first match decided to start blabbing about machine learning and dimensionality reduction algorithms.
And if this wasn't crazy enough, Riley didn't think this person knew what he was talking about.

Can you guess all the possible statements about dimensionality reduction that would make Riley's match incorrect?

1. Supervised learning algorithms can be used as dimensionality reduction techniques.

2. Every dimensionality reduction technique is a clustering technique, but every clustering technique is not a dimensionality reduction algorithm.

3. Dimensionality reduction algorithms are primarily considered unsupervised learning techniques.

4. Nowadays, the most successful dimensionality reduction techniques are deep learning algorithms.
	
## Solution

In machie learning parlence, the number of features in a dataset is called its dimensionality. It turn out some features are correlated (similar) and therefore redundant. We remove feautures that are correlated in our dataset because they will not add any predictive ability to our model. Solution to this is during the data exploration stage, we find correlated feautures and remove them. This process is called "Dimentionality Reduction"

Again, the more feature we have the more difficult it will be for machine learning model to make a correct prediction. This is called the curse of dimensionality reduction. Dataset with hundred or thousands feauturs can be said to have high-dimensionality.

Often, large inputs may leads to have higher parameters in our model, which in turn result in more flexible model that can result in overfitting data (degrees of freedom). Consequently, the model may fail to generalzie on new data. In general, few dimension, generalize better.



Fewer input dimensions often mean correspondingly fewer parameters or a simpler structure in the machine learning model, referred to as degrees of freedom. A model with too many degrees of freedom is likely to overfit the training dataset and therefore may not perform well on new data.



Some of the benefit of dimensionality reduction are: reduction of storage and computation time. 

> "When dealing with high dimensional data, it is often useful to reduce the dimensionality by projecting the data to a lower dimensional subspace which captures the “essence” of the data. This is called dimensionality reduction"

[]




Dimensionality Reduction helps in data compression, and hence reduced storage space. It reduces computation time. It also helps remove redundant features, if any. Dimensionality Reduction helps in data compressing and reducing the storage space required. It fastens the time required for performing same computations




Dimensionality reduction is the task of reducing the number of features in a dataset. In machine learning tasks like regression or classification, there are often too many variables to work with. These variables are also called features.


The number of input variables or features for a dataset is referred to as its dimensionality.

Dimensionality reduction refers to techniques that reduce the number of input variables in a dataset.

More input features often make a predictive modeling task more challenging to model, more generally referred to as the curse of dimensionality.

High-dimensionality statistics and dimensionality reduction techniques are often used for data visualization. Nevertheless these techniques can be used in applied machine learning to simplify a classification or regression dataset in order to better fit a predictive model.

In this post, you will discover a gentle introduction to dimensionality reduction for machine learning





<style>
body {
text-align: justify}
</style>

